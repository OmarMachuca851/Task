{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OmarMachuca851/Task/blob/main/CNN2D_sprint.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81db5ae4",
      "metadata": {
        "id": "81db5ae4"
      },
      "source": [
        "# CNN 2D desde scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a76024ff",
      "metadata": {
        "id": "a76024ff"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "class ReLU:\n",
        "    def forward(self, X):\n",
        "        self.X = X\n",
        "        return np.maximum(0, self.X)\n",
        "\n",
        "    def backward(self, dZ):\n",
        "        return dZ * (self.X > 0).astype(float)\n",
        "\n",
        "\n",
        "class Softmax:\n",
        "    def forward(self, X):\n",
        "        exp_X = np.exp(X - np.max(X, axis=1, keepdims=True))\n",
        "        return exp_X / np.sum(exp_X, axis=1, keepdims=True)\n",
        "\n",
        "    def backward(y_pred, y_true):\n",
        "        batch_size = y_true.shape[0]\n",
        "        grad = y_pred.copy()\n",
        "        grad[range(batch_size), y_true] -= 1\n",
        "        return grad / batch_size\n",
        "\n",
        "\n",
        "class AdaGrad:\n",
        "    def __init__(self, lr):\n",
        "        self.lr = lr\n",
        "        self.HW = 1\n",
        "        self.HB = 1\n",
        "    def update(self, layer):\n",
        "        self.HW += layer.dW**2\n",
        "        self.HB += layer.dB**2\n",
        "        layer.W -= self.lr * np.sqrt(1/self.HW) * layer.dW\n",
        "        layer.b -= self.lr * np.sqrt(1/self.HB) * layer.dB\n",
        "        return layer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f3f99d9",
      "metadata": {
        "id": "3f3f99d9"
      },
      "source": [
        "## Problema 1: Creación de una capa de convolución"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3702f5ce",
      "metadata": {
        "id": "3702f5ce"
      },
      "outputs": [],
      "source": [
        "class Conv2D:\n",
        "    def __init__(self, input_channels, num_filters, kernel_size, lr=0.01, stride=1, padding=0):\n",
        "        self.input_channels = input_channels\n",
        "        self.num_filters = num_filters\n",
        "        self.kh, self.kw = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.AdaGrad = AdaGrad(lr)\n",
        "\n",
        "        # Xavier Initializer\n",
        "        std = np.sqrt(1.0 / (self.kh * self.kw * input_channels))\n",
        "\n",
        "        self.W = np.random.randn(self.kh, self.kw, input_channels, num_filters) * std\n",
        "        self.b = np.zeros((1, 1, 1, num_filters))\n",
        "\n",
        "    # Forward 2D convolution\n",
        "    def forward(self, X):\n",
        "        self.X = X\n",
        "        batch_size, in_height, in_width, in_channels = X.shape\n",
        "\n",
        "        out_height = (in_height + 2 * self.padding - self.kh + 1) // self.stride\n",
        "        out_width = (in_width + 2 * self.padding - self.kw + 1) // self.stride\n",
        "\n",
        "        self.output = np.zeros((batch_size, out_height, out_width, self.num_filters))\n",
        "\n",
        "        if self.padding > 0:\n",
        "            X = np.pad(X, ((0, 0), (self.padding, self.padding), (self.padding, self.padding), (0, 0)), mode='constant')\n",
        "\n",
        "        self.X_padded = X\n",
        "\n",
        "        # Convolution\n",
        "        for i in range(out_height):\n",
        "            for j in range(out_width):\n",
        "                for k in range(self.num_filters):\n",
        "                    h_start = i * self.stride\n",
        "                    h_end = h_start + self.kh\n",
        "                    w_start = j * self.stride\n",
        "                    w_end = w_start + self.kw\n",
        "                    region = X[:, h_start:h_end, w_start:w_end, :]\n",
        "                    self.output[:, i, j, k] = np.sum(region * self.W[:, :, :, k], axis=(1, 2, 3)) + self.b[0, 0, 0, k]\n",
        "\n",
        "        return self.output\n",
        "\n",
        "    # Backward 2D convolution\n",
        "    def backward(self, dZ):\n",
        "        _, out_height, out_width, _ = dZ.shape\n",
        "        dX = np.zeros_like(self.X_padded, dtype=np.float32)\n",
        "        self.dW = np.zeros_like(self.W)\n",
        "        self.dB = np.zeros_like(self.b)\n",
        "\n",
        "        # Gradients\n",
        "        for i in range(out_height):\n",
        "            for j in range(out_width):\n",
        "                for k in range(self.num_filters):\n",
        "                    h_start = i * self.stride\n",
        "                    h_end = h_start + self.kh\n",
        "                    w_start = j * self.stride\n",
        "                    w_end = w_start + self.kw\n",
        "                    region = self.X_padded[:, h_start:h_end, w_start:w_end, :]\n",
        "                    self.dW[:, :, :, k] += np.sum(region * dZ[:, i, j, k][:, None, None, None], axis=0)\n",
        "                    self.dB[0, 0, 0, k] += np.sum(dZ[:, i, j, k])\n",
        "                    dX[:, h_start:h_end, w_start:w_end, :] += self.W[:, :, :, k] * dZ[:, i, j, k][:, None, None, None]\n",
        "\n",
        "        if self.padding > 0:\n",
        "            dX = dX[:, :, self.padding : -self.padding, self.padding : -self.padding]\n",
        "\n",
        "        self.AdaGrad.update(self)\n",
        "\n",
        "        return dX"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c45de219",
      "metadata": {
        "id": "c45de219"
      },
      "source": [
        "## Problema 2: Experimento con capas convolucionales 2D en matrices pequeñas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d5718a9",
      "metadata": {
        "id": "9d5718a9",
        "outputId": "6b0471cd-7048-4ade-dadc-0095b37603bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "forward Output:\n",
            "[[[[-4.  1.]\n",
            "   [-4.  1.]]\n",
            "\n",
            "  [[-4.  1.]\n",
            "   [-4.  1.]]]]\n",
            "\n",
            "Backward Output (dx): \n",
            "[[[[  0.   0.   0.   0.]\n",
            "   [  0.  -5.   4.  -7.]\n",
            "   [  0.  -1.  12. -11.]\n",
            "   [  0.   4.   4.   0.]]]]\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Input data when flowing CNN2 forwards (1, 4, 4, 1)\n",
        "x = np.array([[[[1],[ 2], [3], [4]],\n",
        "                [[5], [6], [7], [8]],\n",
        "                [[9], [10], [11], [12]],\n",
        "                [[13], [14], [15], [16]]]])\n",
        "\n",
        "# Manually setting filters\n",
        "w = np.array([\n",
        "    [[[0, 0]], [[0, 0]], [[0, 0]]],\n",
        "     [[[0, 0]], [[1, -1]], [[0, 1]]],\n",
        "     [[[0, 0]], [[-1, 0]], [[0, 0]]]\n",
        "]).astype(np.float32) # Cast to float\n",
        "\n",
        "b = np.array([[[[0, 0]]]], dtype=np.float32)\n",
        "\n",
        "# Conv2 with 1 input channel , 2 output channels, kernel 3x3\n",
        "conv = Conv2D(input_channels=1, num_filters=2, kernel_size=(3, 3), lr=0.01, stride=1, padding=0)\n",
        "conv.W = w.copy()\n",
        "conv.B = b.copy()\n",
        "\n",
        "# Forward pass\n",
        "out = conv.forward(x)\n",
        "print(f\"forward Output:\\n{out}\")\n",
        "\n",
        "# Backward test\n",
        "dout = np.array([[[[-4, 1], [-4, -7]], [[-4, 1], [-4, -11]]]], dtype=np.float32)\n",
        "dx = conv.backward(dout)\n",
        "print(f'\\nBackward Output (dx): \\n{dx.reshape(1, 1, 4, 4)}')\n",
        "print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ead7b49",
      "metadata": {
        "id": "4ead7b49"
      },
      "source": [
        "## Problema 3: Tamaño de salida después de la convolución 2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "462f9f43",
      "metadata": {
        "id": "462f9f43"
      },
      "outputs": [],
      "source": [
        "def conv2d_output_size(H_in, W_in, kernel_size, stride=1, padding=0):\n",
        "    kh, kw = kernel_size\n",
        "    H_out = (H_in + 2 * padding - kh) // stride + 1\n",
        "    W_out = (W_in + 2 * padding - kw) // stride + 1\n",
        "    return H_out, W_out"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d421f99",
      "metadata": {
        "id": "3d421f99"
      },
      "source": [
        "## Problema 4: Creación de una capa de agrupación máxima"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f315ead9",
      "metadata": {
        "id": "f315ead9"
      },
      "outputs": [],
      "source": [
        "class MaxPool2D:\n",
        "    def __init__(self, pool_size=(2, 2), stride=2):\n",
        "        self.ph, self.pw = pool_size\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, X):\n",
        "        self.X = X\n",
        "        batch_size, in_height, in_width, in_channels = X.shape\n",
        "\n",
        "        out_height = (in_height - self.ph) // self.stride + 1\n",
        "        out_width = (in_width - self.pw) // self.stride + 1\n",
        "\n",
        "        self.output = np.zeros((batch_size, out_height, out_width, in_channels))\n",
        "        self.max_indices = np.zeros((batch_size, out_height, out_width, in_channels, 2), dtype=int)\n",
        "\n",
        "        for i in range(out_height):\n",
        "            for j in range(out_width):\n",
        "                for c in range(in_channels):\n",
        "                    h_start = i * self.stride\n",
        "                    h_end = h_start + self.ph\n",
        "                    w_start = j * self.stride\n",
        "                    w_end = w_start + self.pw\n",
        "\n",
        "                    region = X[:, h_start:h_end, w_start:w_end, c]\n",
        "                    self.output[:, i, j, c] = np.max(region, axis=(1, 2))\n",
        "\n",
        "                    max_indices_flat = np.argmax(region.reshape(batch_size, -1), axis=1)\n",
        "                    for b in range(batch_size):\n",
        "                        h_idx = max_indices_flat[b] // self.ph\n",
        "                        w_idx = max_indices_flat[b] % self.pw\n",
        "                        self.max_indices[b, i, j, c] = [h_start + h_idx, w_start + w_idx]\n",
        "\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, dZ):\n",
        "        batch_size, out_height, out_width, out_channels = dZ.shape\n",
        "        dX = np.zeros_like(self.X)\n",
        "\n",
        "        for i in range(out_height):\n",
        "            for j in range(out_width):\n",
        "                for c in range(out_channels):\n",
        "                    for b in range(batch_size):\n",
        "                        h_idx, w_idx = self.max_indices[b, i, j, c]\n",
        "                        dX[b, h_idx, w_idx, c] += dZ[b, i, j, c]\n",
        "\n",
        "        return dX"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "038aa252",
      "metadata": {
        "id": "038aa252"
      },
      "source": [
        "## Problema 5: Creación de agrupamiento promedio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91eb2def",
      "metadata": {
        "id": "91eb2def"
      },
      "outputs": [],
      "source": [
        "class AveragePool2D:\n",
        "    def __init__(self, pool_size=(2, 2), stride=2):\n",
        "        self.ph, self.pw = pool_size\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.x = x\n",
        "        N, C, H, W = x.shape\n",
        "        out_h = (H - self.ph) // self.stride + 1\n",
        "        out_w = (W - self.pw) // self.stride + 1\n",
        "        self.arg_max = np.zeros((N, C, out_h, out_w), dtype=np.int32)\n",
        "\n",
        "        out = np.zeros((N, C, out_h, out_w))\n",
        "\n",
        "        for n in range(N):\n",
        "            for c in range(C):\n",
        "                for i in range(out_h):\n",
        "                    for j in range(out_w):\n",
        "                        h_start = i * self.stride\n",
        "                        w_start = j * self.stride\n",
        "                        window = x[n, c, h_start : h_start + self.ph, w_start : w_start + self.pw]\n",
        "                        out[n, c, i, j] = np.mean(window)\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        N, C, H, W = self.x.shape\n",
        "        out_h, out_w = dout.shape[2:]\n",
        "        dx = np.zeros_like(self.x)\n",
        "\n",
        "        for n in range(N):\n",
        "            for c in range(C):\n",
        "                for i in range(out_h):\n",
        "                    for j in range(out_w):\n",
        "                        h_start = i * self.stride\n",
        "                        w_start = j * self.stride\n",
        "                        dx[n, c, h_start : h_start + self.ph, w_start : w_start + self.pw] += dout[n, c, i, j] / (self.ph  + self.pw)\n",
        "        return dx"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4373da9",
      "metadata": {
        "id": "d4373da9"
      },
      "source": [
        "## Problema 6: Suavizado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cceeecdb",
      "metadata": {
        "id": "cceeecdb"
      },
      "outputs": [],
      "source": [
        "class Flatten:\n",
        "    def __init__(self):\n",
        "        self.input_shape = None\n",
        "\n",
        "    def forward(self, X):\n",
        "        self.input_shape = X.shape\n",
        "        return X.reshape(X.shape[0], -1)\n",
        "\n",
        "    def backward(self, dZ):\n",
        "        return dZ.reshape(self.input_shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8788a494",
      "metadata": {
        "id": "8788a494"
      },
      "source": [
        "## Problema 7: Aprendizaje y estimación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "599a78fb",
      "metadata": {
        "id": "599a78fb"
      },
      "outputs": [],
      "source": [
        "class Scratch2dCNNClassifier:\n",
        "    def __init__(self, CNN, epochs=10, batch_size=20, verbose=True):\n",
        "        self.layers = CNN\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.verbose = verbose\n",
        "\n",
        "    def forward(self, X):\n",
        "        self.activations = [X]\n",
        "\n",
        "        for layer in self.layers:\n",
        "            output = layer.forward((self.activations[-1]))\n",
        "            self.activations.append(output)\n",
        "\n",
        "        return self.activations[-1]\n",
        "\n",
        "    def backward(self, y_pred, y_true):\n",
        "        grad = Softmax.backward(y_pred, y_true)\n",
        "\n",
        "        for i in range(len(self.layers) - 2, -1, -1):\n",
        "            layer = self.layers[i]\n",
        "            grad = layer.backward(grad)\n",
        "\n",
        "    def cross_entropy_loss(self, y_pred, y_true):\n",
        "        m = y_true.shape[0]\n",
        "        log_likelihood = -np.log(y_pred[range(m), y_true])\n",
        "        return np.sum(log_likelihood) / m\n",
        "\n",
        "    def accuracy(self, y_pred, y_true):\n",
        "        predictions = np.argmax(y_pred, axis=1)\n",
        "        return np.mean(predictions == y_true)\n",
        "\n",
        "    def fit(self, X, y, validation_data=None, verbose=True):\n",
        "        n_samples = X.shape[0]\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "            epoch_loss = 0\n",
        "            indices = np.random.permutation(n_samples)\n",
        "            X_shuffled = X[indices]\n",
        "            y_shuffled = y[indices]\n",
        "\n",
        "            for i in range(0, n_samples, self.batch_size):\n",
        "                X_batch = X_shuffled[i:i+self.batch_size]\n",
        "                y_batch = y_shuffled[i:i+self.batch_size]\n",
        "\n",
        "                # Forward pass\n",
        "                y_pred = self.forward(X_batch)\n",
        "\n",
        "                loss = self.cross_entropy_loss(y_pred, y_batch)\n",
        "                epoch_loss += loss\n",
        "\n",
        "                # Backward pass\n",
        "                self.backward(y_pred, y_batch)\n",
        "\n",
        "            avg_loss = epoch_loss / (n_samples / self.batch_size)\n",
        "\n",
        "            # Validation\n",
        "            if validation_data is not None:\n",
        "                X_val, y_val = validation_data\n",
        "                val_pred = self.forward(X_val)\n",
        "                val_loss = self.cross_entropy_loss(val_pred, y_val)\n",
        "                val_acc = self.accuracy(val_pred, y_val)\n",
        "\n",
        "            if verbose:\n",
        "                if validation_data is not None:\n",
        "                    print(f\"Epoch {epoch+1:3d}/{self.epochs} | \"\n",
        "                          f\"Train Loss: {avg_loss:.4f} | \"\n",
        "                          f\"Val Loss: {val_loss:.4f} | \"\n",
        "                          f\"Val Acc: {val_acc:.4f}\")\n",
        "                else:\n",
        "                    print(f\"Epoch {epoch+1:3d}/{self.epochs} | Train Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        y_pred = self.forward(X)\n",
        "        return np.argmax(y_pred, axis=1)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        return self.forward(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ade58b6",
      "metadata": {
        "id": "5ade58b6"
      },
      "outputs": [],
      "source": [
        "class FC:\n",
        "    def __init__(self, input_size, output_size, lr=0.01):\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "        self.lr = lr\n",
        "        self.AdaGrad = AdaGrad(lr)\n",
        "\n",
        "        # Xavier initializer\n",
        "        std = np.sqrt(1.0 / input_size)\n",
        "\n",
        "        self.W = np.random.randn(input_size, output_size) * std\n",
        "        self.b = np.zeros((1, output_size))\n",
        "\n",
        "    def forward(self, X):\n",
        "        self.X = X\n",
        "        return np.dot(X, self.W) + self.b\n",
        "\n",
        "    def backward(self, dZ):\n",
        "        self.dW = np.dot(self.X.T, dZ)\n",
        "        self.dB = np.sum(dZ, axis=0, keepdims=True)\n",
        "        dX = np.dot(dZ, self.W.T)\n",
        "        self.AdaGrad.update(self)\n",
        "        return dX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9329a7e",
      "metadata": {
        "id": "f9329a7e"
      },
      "outputs": [],
      "source": [
        "def load_and_preprocess_data():\n",
        "    # Loading MNIST data\n",
        "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "    X_train, y_train, X_test, y_test = X_train[:10000], y_train[:10000], X_test[:2000], y_test[:2000]\n",
        "    # Preprocessimg\n",
        "    X_train = X_train.reshape(-1, 28, 28, 1).astype(np.float32) / 255\n",
        "    X_test = X_test.reshape(-1, 28, 28, 1).astype(np.float32) / 255\n",
        "\n",
        "    # Splitting into training and validation sets\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
        "\n",
        "X_train, y_train, X_val, y_val, X_test, y_test = load_and_preprocess_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6427775b",
      "metadata": {
        "id": "6427775b",
        "outputId": "95866a13-ff86-4e91-95ff-5832723117f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch   1/5 | Train Loss: 1.6477 | Val Loss: 0.9615 | Val Acc: 0.8085\n",
            "Epoch   2/5 | Train Loss: 0.7062 | Val Loss: 0.5265 | Val Acc: 0.8715\n",
            "Epoch   3/5 | Train Loss: 0.4794 | Val Loss: 0.4245 | Val Acc: 0.8855\n",
            "Epoch   4/5 | Train Loss: 0.4058 | Val Loss: 0.3759 | Val Acc: 0.9040\n",
            "Epoch   5/5 | Train Loss: 0.3653 | Val Loss: 0.3489 | Val Acc: 0.9035\n",
            "train_accuracy = 0.9049\n",
            "test_accuracy = 0.8660\n"
          ]
        }
      ],
      "source": [
        "CN = [\n",
        "    Conv2D(1, 8, kernel_size=(3, 3), lr=0.01, stride=1, padding=1),\n",
        "    ReLU(),\n",
        "    MaxPool2D(pool_size=(2, 2), stride=2),\n",
        "    Flatten(),\n",
        "    FC(14*14*8, 64),\n",
        "    ReLU(),\n",
        "    FC(64, 10),\n",
        "    Softmax(),\n",
        "]\n",
        "cnn = Scratch2dCNNClassifier(CN, epochs=5, batch_size=50)\n",
        "\n",
        "cnn.fit(X_train, y_train, validation_data=(X_val, y_val))\n",
        "\n",
        "y_train_pred = cnn.predict_proba(X_train)\n",
        "y_test_pred = cnn.predict_proba(X_test)\n",
        "\n",
        "train_accuracy = cnn.accuracy(y_train_pred, y_train)\n",
        "test_accuracy = cnn.accuracy(y_test_pred, y_test)\n",
        "\n",
        "print(f\"{train_accuracy = :.4f}\")\n",
        "print(f\"{test_accuracy = :.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "137adbe2",
      "metadata": {
        "id": "137adbe2"
      },
      "source": [
        "## Problema 8: LeNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08dbfd38",
      "metadata": {
        "id": "08dbfd38",
        "outputId": "2e4fecfd-42fe-43b6-a97b-0e64d6dcb15f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch   1/5 | Train Loss: 0.3423 | Val Loss: 0.3330 | Val Acc: 0.9085\n",
            "Epoch   2/5 | Train Loss: 0.3235 | Val Loss: 0.3153 | Val Acc: 0.9140\n",
            "Epoch   3/5 | Train Loss: 0.3094 | Val Loss: 0.3117 | Val Acc: 0.9145\n",
            "Epoch   4/5 | Train Loss: 0.2977 | Val Loss: 0.2965 | Val Acc: 0.9190\n",
            "Epoch   5/5 | Train Loss: 0.2860 | Val Loss: 0.2900 | Val Acc: 0.9185\n",
            "train_accuracy = 0.9230\n",
            "test_accuracy = 0.8820\n"
          ]
        }
      ],
      "source": [
        "LeNet = [\n",
        "    Conv2D(1, 6, kernel_size=(5, 5), lr=0.01, stride=1, padding=0),\n",
        "    ReLU(),\n",
        "    MaxPool2D(pool_size=(2, 2), stride=2),\n",
        "    Conv2D(6, 16, kernel_size=(5, 5), lr=0.01, stride=1, padding=0),\n",
        "    ReLU(),\n",
        "    MaxPool2D(pool_size=(2, 2), stride=2),\n",
        "    Flatten(),\n",
        "    FC(16*4*4, 200),\n",
        "    ReLU(),\n",
        "    FC(200, 120),\n",
        "    ReLU(),\n",
        "    FC(120, 10),\n",
        "    Softmax(),\n",
        "]\n",
        "cnn = Scratch2dCNNClassifier(CN, epochs=5, batch_size=50)\n",
        "\n",
        "cnn.fit(X_train, y_train,validation_data=(X_val, y_val))\n",
        "\n",
        "y_train_pred = cnn.predict_proba(X_train)\n",
        "y_test_pred = cnn.predict_proba(X_test)\n",
        "\n",
        "train_accuracy = cnn.accuracy(y_train_pred, y_train)\n",
        "test_accuracy = cnn.accuracy(y_test_pred, y_test)\n",
        "\n",
        "print(f\"{train_accuracy = :.4f}\")\n",
        "print(f\"{test_accuracy = :.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbc41c8d",
      "metadata": {
        "id": "dbc41c8d"
      },
      "source": [
        "## Problema 9: Investigación sobre modelos famosos de reconocimiento de imágenes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6084c336",
      "metadata": {
        "id": "6084c336"
      },
      "source": [
        "- **LeNet-5 (1998):**\n",
        "LeNet-5, una red convolucional pionera de 7 niveles, creada por LeCun et al. en 1998 y que clasifica dígitos, fue aplicada por varios bancos para reconocer números manuscritos en cheques digitalizados en imágenes de entrada en escala de grises de 32x32 píxeles. La capacidad de procesar imágenes de mayor resolución requiere capas más grandes y convolucionales, por lo que esta técnica está limitada por la disponibilidad de recursos informáticos.\n",
        "\n",
        "- **AlexNet (2012):**\n",
        "En 2012, AlexNet superó significativamente a todos sus competidores anteriores y ganó el desafío al reducir el error del top 5 del 26 % al 15,3 %. La tasa de error del top 5, que obtuvo el segundo puesto y que no fue una variación de CNN, fue de alrededor del 26,2 %.\n",
        "La red tenía una arquitectura muy similar a la de LeNet de Yann LeCun et al., pero era más profunda, con más filtros por capa y capas convolucionales apiladas. Consistía en convoluciones de 11x11, 5x5 y 3x3, agrupamiento máximo, abandono, aumento de datos, activaciones ReLU y SGD con momentum. Incorporaba activaciones ReLU después de cada capa convolucional y completamente conectada. AlexNet se entrenó durante 6 días simultáneamente en dos GPU Nvidia GeForce GTX 580, razón por la cual su red se divide en dos pipelines. AlexNet fue diseñada por el grupo SuperVision, compuesto por Alex Krizhevsky, Geoffrey Hinton e Ilya Sutskever.\n",
        "\n",
        "- **ZFNet (2013):**\n",
        "Como era de esperar, el ganador del ILSVRC 2013 también fue una CNN conocida como ZFNet. Logró una tasa de error del 14,8 %, que se encuentra entre las 5 mejores, lo que representa la mitad de la tasa de error no neuronal mencionada anteriormente. Este logro se logró principalmente mediante la optimización de los hiperparámetros de AlexNet, manteniendo la misma estructura con elementos adicionales de aprendizaje profundo, como se mencionó anteriormente en este ensayo.\n",
        "\n",
        "- **GoogleNet/Origen (2014):**\n",
        "El ganador de la competición ILSVRC 2014 fue GoogLeNet (también conocido como Inception V1) de Google. ¡Logró una tasa de error del 6,67%, entre las 5 mejores! Esto se acercaba mucho al rendimiento humano, que los organizadores del desafío ahora debían evaluar. Resultó ser bastante difícil y requirió entrenamiento humano para superar la precisión de GoogLeNet. Tras unos días de entrenamiento, el experto (Andrej Karpathy) logró una tasa de error del 5,1% (modelo único) y del 3,6% (modelo conjunto), entre las 5 mejores. La red utilizó una CNN inspirada en LeNet, pero implementó un elemento novedoso denominado módulo Inception. Utilizaba normalización por lotes, distorsiones de imagen y RMSprop. Este módulo se basa en varias convoluciones muy pequeñas para reducir drásticamente el número de parámetros. Su arquitectura consistía en una CNN de 22 capas, pero redujo el número de parámetros de 60 millones (AlexNet) a 4 millones.\n",
        "\n",
        "- **VGGNet (2014):**\n",
        "El subcampeón de la competencia ILSVRC 2014, VGGNet, fue desarrollado por Simonyan y Zisserman y bautizado por la comunidad como VGGNet. VGGNet consta de 16 capas convolucionales y es muy atractivo gracias a su arquitectura uniforme. Similar a AlexNet, solo convoluciones 3x3, pero con numerosos filtros. Se entrenó en 4 GPU durante 2-3 semanas. Actualmente, es la opción preferida de la comunidad para extraer características de imágenes. La configuración de pesos de VGGNet está disponible públicamente y se ha utilizado en muchas otras aplicaciones y desafíos como extractor de características de referencia. Sin embargo, VGGNet consta de 138 millones de parámetros, lo que puede resultar un poco complejo de manejar.\n",
        "\n",
        "- **ResNet (2015):**\n",
        "Finalmente, en el ILSVRC 2015, la denominada Red Neuronal Residual (ResNet) de Kaiming He et al. introdujo una novedosa arquitectura con conexiones de salto y una alta normalización por lotes. Estas conexiones de salto, también conocidas como unidades con compuerta o unidades recurrentes con compuerta, presentan una gran similitud con elementos recientes y exitosos aplicados en las redes neuronales recurrentes (RNN). Gracias a esta técnica, lograron entrenar una red neuronal con 152 capas, manteniendo una complejidad menor que la de VGGNet. Alcanza una tasa de error del 3,57 %, dentro de los 5 primeros, lo que supera el rendimiento humano en este conjunto de datos.\n",
        "\n",
        "AlexNet tiene dos líneas CNN paralelas de entrenadas en dos GPU con conexiones cruzadas, GoogleNet tiene módulos de inicio y ResNet tiene conexiones residuales."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1eda69b",
      "metadata": {
        "id": "b1eda69b"
      },
      "source": [
        "## Problema 10: Cálculo del tamaño de salida y el número de parámetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a92f3921",
      "metadata": {
        "id": "a92f3921",
        "outputId": "6d2b8468-0f74-4065-c8ed-03b73edaae45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layer 1 Output:(142, 142, 6) Params:168\n",
            "Layer 1 Output:(58, 58, 48) Params:10416\n",
            "Layer 1 Output:(9, 9, 20) Params:1820\n"
          ]
        }
      ],
      "source": [
        "def compute_conv_output_and_params(H_in, W_in, C_in, kernel_size, C_out, stride=1, padding=0):\n",
        "    kh, kw = kernel_size\n",
        "\n",
        "    # Output dimensions\n",
        "    H_out = (H_in + 2 * padding - kh) // stride + 1\n",
        "    W_out = (W_in + 2 * padding - kw) // stride + 1\n",
        "\n",
        "    # Parameters per filter: C_in * kh * Kw, plus 1 bias output channel\n",
        "    params_per_filter = C_in * kh * kw + 1\n",
        "    total_params = params_per_filter * C_out\n",
        "\n",
        "    return (H_out, W_out, C_out), total_params\n",
        "\n",
        "# 1. Input: 144x144x3, filter 3x3, 6 filters, stride=1, pading=0\n",
        "out_size1, params1 = compute_conv_output_and_params(144, 144, 3, (3, 3), 6)\n",
        "print(f\"Layer 1 Output:{out_size1} Params:{params1}\")\n",
        "\n",
        "# 1. Input: 60x60x24, filter 3x3, 48 filters, stride=1, pading=0\n",
        "out_size2, params2 = compute_conv_output_and_params(60, 60, 24, (3, 3), 48)\n",
        "print(f\"Layer 1 Output:{out_size2} Params:{params2}\")\n",
        "\n",
        "# 1. Input: 20x20x10, filter 3x3, 20 filters, stride=, pading=0\n",
        "out_size3, params3 = compute_conv_output_and_params(20, 20, 10, (3, 3), 20, stride=2)\n",
        "print(f\"Layer 1 Output:{out_size3} Params:{params3}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3074290",
      "metadata": {
        "id": "c3074290"
      },
      "source": [
        "## Problema 11: sobre el tamaño de filtors"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cac4270",
      "metadata": {
        "id": "9cac4270"
      },
      "source": [
        "- **¿Por qué los filtros 3x3 se utilizan comunmente en lugar de los mas gerandes como 7x7?**\n",
        "\n",
        "El uso de los filtros convolucionales de menor tamaño,por ejemplo 3x3 en lugar de grandes filtros convolucionales, por ejemplo 7x7, es convención común de las recientes arquitecturas de CNN dedido a multiples razones, primero el apilamiento residual con varias capas compuestas de filtros 3x3 es más no lineal para la red. Las funciones de activación ocurren despues de cada capa, por lo tanto, con tres capas 3x3 se pueden realizar mas operaciones de activación que con una capa 7x7, y de esta manera son posibles redes mas profundas y expresivas. En segundo lugar los filtros 3x3 tienen un mejor uso de parámetros, por ejemplo en esta capa de 7x7 con canales de entrada y salida, se tendría 49C 2 parámetros, pero con 3 capas convolucionales 3x3 apilados uno encima de otro solo necesitariamos 27C 2 parámetros. Las 3 capas 3x3 puede abarcar el mismo campo de influencia que dos capas 7x7 a pesar del número de parametros reducidos, La red podría comprender la misma información espacial con el beneficio de marginal mente más capacidades de aprendizaje y menos cálculos.\n",
        "\n",
        "- **efecto de un filtor 1x1 sin altura ni ancho:**\n",
        "\n",
        "un filtro de convcolución 1x1 sin altura ni ancho no puede extraer información espacial. Mas bien, actua sobre la dimensión del canal y tiene el efecto de realizar instantaneamente una capa totalmente conectada en cada posición de píxeles en la imagen. Las aplicaciones primarias de un filtor 1x1 son: reducción de la dimensionalidad de entrada, Reducción de lnúmero de canales antes de someterse a una convolución mas compleja en terminos de cálculos e integrar la red con profundidad adicional sin expandirla espacialmente. Además, el aprendisaje de la convinación no lineal en los canales de caracteristicas se pueden hacer usando filtros 1x1. La idea fue concebida  en la arquitectura de la red (NIN) y ha sido implementado con éxito por GoogleNet, en el que fue fundamental para reducir la pronfundidad de las redes y mejorar la eficiente."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "python312",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}